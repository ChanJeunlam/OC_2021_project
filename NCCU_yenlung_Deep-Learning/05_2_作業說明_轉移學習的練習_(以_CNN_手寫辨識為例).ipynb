{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "05-2. 作業說明_轉移學習的練習 (以 CNN 手寫辨識為例).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ja754969/OC_2021_project/blob/practice-and-read/NCCU_yenlung_Deep-Learning/05_2_%E4%BD%9C%E6%A5%AD%E8%AA%AA%E6%98%8E_%E8%BD%89%E7%A7%BB%E5%AD%B8%E7%BF%92%E7%9A%84%E7%B7%B4%E7%BF%92_(%E4%BB%A5_CNN_%E6%89%8B%E5%AF%AB%E8%BE%A8%E8%AD%98%E7%82%BA%E4%BE%8B).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI5sl1w-eYIv"
      },
      "source": [
        "# 主題 05-2. 轉移學習的練習\n",
        "\n",
        "【註】因 TensorFlow 2 已做了一些改變, 例如完全整合了 Keras。到 2021 年的今天, 有一些細節也做了調整。因此我們依新的規範修改了程式。最大的不同是, 以後大家直接安裝 tensorflow 即可, 不用再另外裝 keras。\n",
        "\n",
        "讓我們回顧一下生命中第一個做出來的 CNN 圖形辨識模型..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BqhJfJzeYIw"
      },
      "source": [
        "## 1. 初始準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0a43zzdeYIw"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjQf5fWQeYIx"
      },
      "source": [
        "# tf.Keras functions\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# tf.Keras dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Keras utilis function\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCi46rABeYIx"
      },
      "source": [
        "## 2. 讀入 MNIST 數據庫\n",
        "\n",
        "MNIST 是有一堆 0-9 的手寫數字圖庫。有 6 萬筆訓練資料, 1 萬筆測試資料。它是 \"Modified\" 版的 NIST 數據庫, 原來的版本有更多資料。這個 Modified 的版本是由 LeCun, Cortes, 及 Burges 等人做的。可以參考這個數據庫的[原始網頁](http://yann.lecun.com/exdb/mnist/)。\n",
        "\n",
        "MNIST 可以說是 Deep Learning 最有名的範例, 它被 Deep Learning 大師 Hinton 稱為「機器學習的果蠅」。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0itOW3c_eYIx"
      },
      "source": [
        "### 2.1 由 tf.Keras 讀入 MNIST\n",
        "tf.Keras 很貼心的幫我們準備好 MNIST 數據庫, 我們可以這樣讀進來 (第一周課程中已經讀過)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgexa1N3eYIx"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzRtO-fBeYIx"
      },
      "source": [
        "我們可以看看資料的長相"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB96RgpSeYIx",
        "outputId": "caa0a6ce-64d8-4981-eef1-b017d72da2af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"There are %d training data with size %d x %d\" %x_train.shape)\n",
        "print(\"There are %d testing  data with size %d x %d\" %x_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 60000 training data with size 28 x 28\n",
            "There are 10000 testing  data with size 28 x 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuKH1NlGeYIy"
      },
      "source": [
        "### 2.3 輸入格式整理\n",
        "\n",
        "我們現在要用 CNN 學手寫辨識。因為 CNN 模型的資料需要多一個 channel (通道數)，因此我們要用 `reshape` 調校一下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNwg-_ZReYIy"
      },
      "source": [
        "x_train = x_train.reshape(60000, 28, 28, 1)/255\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)/255"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uLDbPpEeYIy"
      },
      "source": [
        "為了後面需要，我們先將數字 0 和 1 的資料分別抓出來"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYhD6V7keYIy"
      },
      "source": [
        "x_train_01 = x_train[y_train <= 1]\n",
        "x_test_01 = x_test[y_test <= 1]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WMr5dDEeYIy"
      },
      "source": [
        "並將 label 轉換成 one-hot encoding 的形式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54LEGfrueYIy"
      },
      "source": [
        "y_train_10 = to_categorical(y_train, 10)\n",
        "y_test_10 = to_categorical(y_test, 10)\n",
        "\n",
        "y_train_01 = y_train[y_train <= 1]\n",
        "y_train_01 = to_categorical(y_train_01, 2)\n",
        "\n",
        "y_test_01 = y_test[y_test <= 1]\n",
        "y_test_01 = to_categorical(y_test_01, 2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_vS8NLseYIy"
      },
      "source": [
        "養成良好的習慣，適時的確認資料的大小以確保資料的一致性"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T10lPiheYIy",
        "outputId": "1497c906-d012-47b1-b0de-8c8a96971c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train_01.shape, x_test_01.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12665, 28, 28, 1), (2115, 28, 28, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfYdeZVkeYIz",
        "outputId": "592c5cef-2379-4de0-ac53-e6d4f15d81b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train_01.shape, y_test_01.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12665, 2), (2115, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Shf3hLeYIz"
      },
      "source": [
        "# 3. 回顧 CNN 圖形辨識模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAIkQf5keYIz"
      },
      "source": [
        "經典的 CNN 圖形辨識模型 LeNet-5 是一個由兩層卷積層加三層全連接層所建立的神經網路，而在第二單元時，我們建立的 CNN 模型設定如下：\n",
        "\n",
        "* 起始為 <span style=\"color:red;\">3</span> 個 convolutional block\n",
        " + 每個 convolutional block 為 <span style=\"color:red;\">1</span> 個 2D Convolution + ReLU + <span style=\"color:red;\">1</span> 個 2D MaxPooling\n",
        " + 2D Convolution 的數量為 32, 64, 128\n",
        " + 每個 2D Convolution 的 `kernal_size` 為 3 或 (3, 3)，`padding` 使用 `same`\n",
        " + 每個 2D MaxPooling 的 `pool_size` 為 2 或 (2, 2)，`padding` 使用 `same`\n",
        "\n",
        "* 將輸出結果 `Flatten` 後，接著兩層全連接層，神經元個數分別為 200 和 10 (<span style=\"color:red;\">數字的類別總數)</span>\n",
        "\n",
        "我們當時建立的，是一個具有三層卷積層加兩層全連接的神經網路，其實可以看成是 LeNet-5 的一種變形。\n",
        "\n",
        "根據本單元的內容，我們可以使用下列方式使用 Sequential 重新建構第二單元的 CNN 模型。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xo10nTXeYIz",
        "outputId": "a9f9d1b6-883d-4bdf-e556-18ab2cf6c567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We put 3 conv. blocks together, called conv_layer.\n",
        "conv_layer = [Conv2D(32, (3, 3), padding='same', input_shape=(28,28,1)),\n",
        "              Activation('relu'),\n",
        "              MaxPooling2D(pool_size=(2, 2)),\n",
        "              \n",
        "              Conv2D(64, (3, 3), padding='same'),\n",
        "              Activation('relu'),\n",
        "              MaxPooling2D(pool_size=(2, 2)),\n",
        "              \n",
        "              Conv2D(128, (3, 3), padding='same'),\n",
        "              Activation('relu'),\n",
        "              MaxPooling2D(pool_size=(2, 2))]\n",
        "\n",
        "# We put Flatten, and 2 fully-connectd layers together, called fc_layer.\n",
        "fc_layer = [Flatten(),\n",
        "            Dense(200),\n",
        "            Activation('relu'),\n",
        "            Dense(10),\n",
        "            Activation('softmax')]\n",
        "\n",
        "model = Sequential(conv_layer + fc_layer)\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               230600    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2010      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 325,282\n",
            "Trainable params: 325,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdsuMlvteYIz"
      },
      "source": [
        "model.load_weights('handwriting_weights_cnn.h5')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHnhEQHKeYIz"
      },
      "source": [
        "# 4. 保留前三層 convolutional layer 並進行轉移學習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYkoliTEeYI0"
      },
      "source": [
        "在此，我們一樣將 MNIST 資料集將僅有 0, 1的部分取出來，我們希望透過轉移學習建立一個類似 LeNet-5 的 0, 1 圖形辨識模型。\n",
        "\n",
        "請將下列三個 **None** 的部分進行修改，以透過轉移學習建立新的模型。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P83Q6wXJeYI0",
        "outputId": "62482572-0119-44c4-ab37-6a88021da314",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_fc_layer = [Flatten(), \n",
        "                ### Design your own fully connected structures ###\n",
        "                Dense(200),\n",
        "                Activation('sigmoid'),\n",
        "                Dense(2),       ## Hint: how many classes in new dataset?\n",
        "                ### Remember put correct number of unit for output ###\n",
        "                Activation('softmax')]\n",
        "\n",
        "model_0_to_1 = Sequential(conv_layer + new_fc_layer)\n",
        "model_0_to_1.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 200)               230600    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 402       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 323,674\n",
            "Trainable params: 323,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHOZV1QreYI0"
      },
      "source": [
        "請將下列的 **None** 進行修改，以將借過來的神經網路 **冷凍** 起來："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHqUgVOTeYI0"
      },
      "source": [
        "for layer in conv_layer:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrylIus9eYI0"
      },
      "source": [
        "**冷凍**後的神經網路的 summary 會有些變化，你有發現嗎? ：)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUH0CqhWeYI0",
        "outputId": "5e511fe1-51f5-447a-d2d2-39eec6ec3424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_0_to_1.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 200)               230600    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 402       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 323,674\n",
            "Trainable params: 231,002\n",
            "Non-trainable params: 92,672\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YbGcTm-eYI0"
      },
      "source": [
        "接著，我們來訓練這個(有一部分架構及權重跟別人借用的) 0, 1 手寫辨識模型吧！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce_Nqx6ZeYI0"
      },
      "source": [
        "model_0_to_1.compile(loss='mse', optimizer=SGD(learning_rate=0.1), metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EPvKKSLeYI0"
      },
      "source": [
        "## 5. 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKwx0CEbeYI0",
        "outputId": "bbfd5885-f972-4e33-ebd5-f090416d391d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_0_to_1.fit(x_train_01, y_train_01, batch_size=100, epochs=5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "127/127 [==============================] - 7s 47ms/step - loss: 0.0298 - accuracy: 0.9619\n",
            "Epoch 2/5\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.0047 - accuracy: 0.9956\n",
            "Epoch 3/5\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.0036 - accuracy: 0.9961\n",
            "Epoch 4/5\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.0030 - accuracy: 0.9972\n",
            "Epoch 5/5\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.0026 - accuracy: 0.9974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f43a9849a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBJHss9beYI1",
        "outputId": "42169187-50c3-497b-c1b5-f8ae656b6ed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model_0_to_1.evaluate(x_test_01, y_test_01)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67/67 [==============================] - 1s 16ms/step - loss: 0.0016 - accuracy: 0.9981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QSbXnBheYI1",
        "outputId": "2c962d78-62d4-4436-ac3a-6c9b8edbc278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('測試資料的 loss:', score[0])\n",
        "print('測試資料正確率:', score[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "測試資料的 loss: 0.0015654639573767781\n",
            "測試資料正確率: 0.9981087446212769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2suTI9eeYI1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaIY_zEGeYI1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9KDfp81eYI1"
      },
      "source": [
        "## 6. 恭喜你完成了第二個透過轉移學習得到的神經網路模型！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SHCa9CjeYI1"
      },
      "source": [
        "不難發現，如果模型大部分的權重已經訓練好並冷凍起來，則轉移學習可以大幅減少訓練時間且訓練會更快收斂，那麼，是否還有其他重要的模型建構技巧呢？\n",
        "\n",
        "這個問題我們留待下個單元解答囉~ : )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3-1fm-BeYI1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}