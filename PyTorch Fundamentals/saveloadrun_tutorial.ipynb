{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "saveloadrun_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ja754969/OC_2021_project/blob/practice-and-read/PyTorch%20Fundamentals/saveloadrun_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c68yZjKpmigI"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clfbO17FmigI"
      },
      "source": [
        "\n",
        "`Learn the Basics <intro.html>`_ ||\n",
        "`Quickstart <quickstart_tutorial.html>`_ || \n",
        "`Tensors <tensorqs_tutorial.html>`_ || \n",
        "`Datasets & DataLoaders <data_tutorial.html>`_ ||\n",
        "`Transforms <transforms_tutorial.html>`_ ||\n",
        "`Build Model <buildmodel_tutorial.html>`_ ||\n",
        "`Autograd <autogradqs_tutorial.html>`_ ||\n",
        "`Optimization <optimization_tutorial.html>`_ ||\n",
        "**Save & Load Model**\n",
        "\n",
        "Save and Load the Model\n",
        "============================\n",
        "\n",
        "In this section we will look at how to persist model state with saving, loading and running model predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvGfAbaCmigJ"
      },
      "source": [
        "import torch\n",
        "import torch.onnx as onnx\n",
        "import torchvision.models as models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyCLDPvxmigK"
      },
      "source": [
        "Saving and Loading Model Weights\n",
        "--------------------------------\n",
        "PyTorch models store the learned parameters in an internal\n",
        "state dictionary, called ``state_dict``. These can be persisted via the ``torch.save``\n",
        "method:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajSDaCPCmigL"
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhw798OCmigL"
      },
      "source": [
        "To load model weights, you need to create an instance of the same model first, and then load the parameters \n",
        "using ``load_state_dict()`` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLtvbX-5migM"
      },
      "source": [
        "model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpNzKUsAmigM"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>be sure to call ``model.eval()`` method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttRJje61migM"
      },
      "source": [
        "Saving and Loading Models with Shapes\n",
        "-------------------------------------\n",
        "When loading model weights, we needed to instantiate the model class first, because the class \n",
        "defines the structure of a network. We might want to save the structure of this class together with \n",
        "the model, in which case we can pass ``model`` (and not ``model.state_dict()``) to the saving function:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krjAIXnWmigN"
      },
      "source": [
        "torch.save(model, 'model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-JzMJ-RmigN"
      },
      "source": [
        "We can then load the model like this:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W_IF62QmigN"
      },
      "source": [
        "model = torch.load('model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZyH4lUbmigO"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>This approach uses Python `pickle <https://docs.python.org/3/library/pickle.html>`_ module when serializing the model, thus it relies on the actual class definition to be available when loading the model.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXQqXLymmigO"
      },
      "source": [
        "Exporting Model to ONNX\n",
        "-----------------------\n",
        "PyTorch also has native ONNX export support. Given the dynamic nature of the\n",
        "PyTorch execution graph, however, the export process must\n",
        "traverse the execution graph to produce a persisted ONNX model. For this reason, a\n",
        "test variable of the appropriate size should be passed in to the\n",
        "export routine (in our case, we will create a dummy zero tensor of the correct size):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oNi-CwHmigO"
      },
      "source": [
        "input_image = torch.zeros((1,3,224,224))\n",
        "onnx.export(model, input_image, 'model.onnx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FrA4uOkmigP"
      },
      "source": [
        "There are a lot of things you can do with ONNX model, including running inference on different platforms \n",
        "and in different programming languages. For more details, we recommend \n",
        "visiting `ONNX tutorial <https://github.com/onnx/tutorials>`_.\n",
        "\n",
        "Congratulations! You have completed the PyTorch beginner tutorial! Try \n",
        "`revisting the first page <quickstart_tutorial.html>`_ to see the tutorial in its entirety\n",
        "again. We hope this tutorial has helped you get started with deep learning on PyTorch. \n",
        "Good luck!\n",
        "\n",
        "\n"
      ]
    }
  ]
}